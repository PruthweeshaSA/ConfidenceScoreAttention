{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52ba0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_cat_name_lower = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0db72dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/apple'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "user_name = os.path.dirname(os.path.realpath(sys.argv[0])).split('/')[2]\n",
    "user_home = f'/home/{user_name}'\n",
    "user_home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc7afa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "l1_cat_lc = l1_cat_name_lower\n",
    "sys.path.insert(1, f'user_home')\n",
    "\n",
    "# from roberta_l2_unpack_wip_new import load_ckp, RoBERTaClass, CustomDataset\n",
    "# from roberta_l2_unpack_wip_new import RoBERTaClass, CustomDataset\n",
    "\n",
    "RoBERTaClass = getattr(importlib.import_module(f\"roberta_clt_{l1_cat_lc}_training\"), 'RoBERTaClass')\n",
    "CustomDataset = getattr(importlib.import_module(f\"roberta_clt_{l1_cat_lc}_training\"), 'CustomDataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baa4a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dir_path=f\"\"\n",
    "validation_case_level_path = f\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a1a236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6875ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(1)\n",
    "\n",
    "import regex as re\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from transformers import RobertaTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae371cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    \n",
    "    text = re.sub('[0-9]', '', text)                  # remove numbers  \n",
    "    text = re.sub(' +', ' ', text)                    # remove multiple whitespaces\n",
    "    text = text.replace(\"'\", \"\")                      # remove apostrophe\n",
    "    text = re.sub('[-!,;+\"%>|<@:#_=$Â£/*]', ' ', text) # remove special characters \n",
    "    text = re.sub(r\"[\\([{})\\]]\", \" \", text)           # remove brackets \n",
    "    text = text.replace(\"\\n\", \".\" )                   # replace newline with .\n",
    "    text = text.replace(\"\\t\", \"\" )                    # replace '?' with whitespace\n",
    "    text = text.replace('?', ' ') \n",
    "    text = text.replace('e.g.', ' ')                  # remove elements like e.g., i.e., etc.\n",
    "    text = text.replace('i.e.', ' ')\n",
    "    text = text.replace('etc.', ' ') \n",
    "    text = text.replace(\"x000D\", \".\" )  \n",
    "    text = text.replace(\"Seperator\", \".\" ) \n",
    "    text = text.lower()                               # convert all text to lowercase\n",
    "    text = nltk.sent_tokenize(text) \n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54b72d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentence_level_path = f\"\"\n",
    "df_train = pd.read_csv(train_sentence_level_path,index_col=False)\n",
    "if 'Unnamed: 0' in df_train.columns:\n",
    "    df_train=df_train.drop('Unnamed: 0',axis=1)\n",
    "# sorted(df_train['label'].unique().tolist())\n",
    "target_list = sorted(df_train['label'].value_counts().index)\n",
    "target_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5777ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_train['label'].value_counts()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6361538",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = pd.read_csv(validation_case_level_path, index_col=False)\n",
    "if 'Unnamed: 0' in df_val.columns:\n",
    "    df_val=df_val.drop('Unnamed: 0',axis=1)\n",
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ceab7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df_val[''].value_counts(),\n",
    "    sum(df_val[''].value_counts())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161ceb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562ed0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_label_list=[]\n",
    "case_category_list=[]\n",
    "for index in range(df_val.shape[0]):\n",
    "    label = 'noise'\n",
    "    l1_cat_string = ''\n",
    "   # l2_cat_string = 'Contact reason 2nd level'\n",
    "    row=df_val.iloc[index]\n",
    "    case_number=str(row[''])\n",
    "    text = str(row[''])\n",
    "    text += str(row['']) \n",
    "    text = text + str(row[''])\n",
    "    text = text + str(row[''])\n",
    "    text = text + str(row[''])\n",
    "    \n",
    "    # text = str(row['Trigger sentences'])\n",
    "    # if (row[l1_cat_string] == l1_category_name):\n",
    "    label = row[l1_cat_string]\n",
    "    text_label_list.append({'case_number':case_number, 'text': text, 'label': label})\n",
    "df_val_v1=pd.DataFrame(text_label_list)\n",
    "df_val_v1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d547062b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_val_v1 = df_val_v1.loc[:, ['text', 'label']]\n",
    "df_val_v1.dropna(subset=['text'], inplace=True)\n",
    "df_val_v1 = df_val_v1.reset_index(drop=True)\n",
    "df_val_v1[189:290]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6248e5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxindex(data_list):\n",
    "    index=0\n",
    "    for i in range(len(data_list)):\n",
    "        if (data_list[i]>data_list[index]):\n",
    "            index=i\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5185ebb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentence_level_path = f\"\"\n",
    "df_train = pd.read_csv(train_sentence_level_path, index_col=False)\n",
    "df_train=df_train.reset_index(drop=True)\n",
    "df_train['label'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b02584f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target_list = sorted(df_train['label'].value_counts().index)\n",
    "import gc\n",
    "del df_train\n",
    "gc.collect()\n",
    "\n",
    "target_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce0046d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "MAX_LEN = 256\n",
    "# TRAIN_BATCH_SIZE = 8\n",
    "# VALID_BATCH_SIZE = 8\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 4\n",
    "EPOCHS = 15\n",
    "LEARNING_RATE = 1e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be43cc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tagged_dataset(df_val_v1):\n",
    "    case_tags_val = pd.get_dummies(df_val_v1.label, dtype=int)\n",
    "    case_tags_val_columns = case_tags_val.columns.tolist()\n",
    "    # to add missing columns in validation dataframe \n",
    "    for column in target_list:\n",
    "        if column not in case_tags_val_columns:\n",
    "            case_tags_val[column]=pd.Series(0,index=range(case_tags_val.shape[0]))\n",
    "    case_tags_val_columns = sorted(case_tags_val.columns.tolist())\n",
    "    case_tags_val=case_tags_val[case_tags_val_columns]\n",
    "\n",
    "    df_val_v2 = pd.concat([df_val_v1, case_tags_val], axis=1)\n",
    "    return df_val_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81ef882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_case_category(model, device, case_data_loader):\n",
    "    optimizer = torch.optim.AdamW(params =  model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    output_categories=[]\n",
    "    output_list=[]\n",
    "    for batch_idx, data in enumerate(case_data_loader):\n",
    "        #print('yyy epoch', batch_idx)\n",
    "        # print(data['input_ids'])\n",
    "        ids = data['input_ids'].to(device, dtype = torch.long)\n",
    "        mask = data['attention_mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.float)\n",
    "\n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "        for output in outputs:\n",
    "            output_list.append(output)\n",
    "        print(output_list)\n",
    "    return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f606d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val_v1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765b404a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ckp(checkpoint_fpath, model, optimizer):\n",
    "    \"\"\"\n",
    "    checkpoint_path: path to save checkpoint\n",
    "    model: model that we want to load checkpoint parameters into       \n",
    "    optimizer: optimizer we defined in previous training\n",
    "    \"\"\"\n",
    "    # load check point\n",
    "    checkpoint = torch.load(checkpoint_fpath)\n",
    "    # initialize state_dict from checkpoint to model\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    # initialize optimizer from checkpoint to optimizer\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    # initialize valid_loss_min from checkpoint to valid_loss_min\n",
    "    valid_loss_min = checkpoint['valid_loss_min']\n",
    "    # return model, optimizer, epoch value, min validation loss \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b23e37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise_index = target_list.index('noise')\n",
    "# print(noise_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0217be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation_case_level_path = f\"{processed_dir_path}/Common/val_cases.csv\"\n",
    "val_df = pd.read_csv(validation_case_level_path)\n",
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec76110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download(\"punkt\")\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e529f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187bcf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Reevu's code snippet refactored to populate confusion matrix\n",
    "#######################################################################\n",
    "\n",
    "\n",
    "# target_cols = ['availability', 'compatibility_of_parts', 'features/benefits', 'noise', 'order_product', 'order_status', 'price',\n",
    "#                'product_information']\n",
    "\n",
    "\n",
    "target_cols = target_list\n",
    "\n",
    "output_list = []\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "\n",
    "model = RoBERTaClass()\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(params =  model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "model=load_ckp(best_model_path,model,optimizer)\n",
    "\n",
    "confusion_matrix = pd.DataFrame(0,index=target_list,columns=target_list)\n",
    "\n",
    "TP=0\n",
    "FP=0\n",
    "TN=0\n",
    "FN=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af135b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_target_list=[]\n",
    "for i in range(0,8):\n",
    "    dummy_target_list += [f\"C{i+1}\"]\n",
    "dummy_target_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ab9a975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&lt;1%</th>\n",
       "      <th>1%-10%</th>\n",
       "      <th>10%-20%</th>\n",
       "      <th>20%-30%</th>\n",
       "      <th>30%-40%</th>\n",
       "      <th>40%-50%</th>\n",
       "      <th>50%-60%</th>\n",
       "      <th>60%-70%</th>\n",
       "      <th>70%-80%</th>\n",
       "      <th>80%-90%</th>\n",
       "      <th>90%-100%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    <1%  1%-10%  10%-20%  20%-30%  30%-40%  40%-50%  50%-60%  60%-70%  \\\n",
       "C1    0       0        0        0        0        0        0        0   \n",
       "C2    0       0        0        0        0        0        0        0   \n",
       "C3    0       0        0        0        0        0        0        0   \n",
       "C4    0       0        0        0        0        0        0        0   \n",
       "C5    0       0        0        0        0        0        0        0   \n",
       "C6    0       0        0        0        0        0        0        0   \n",
       "C7    0       0        0        0        0        0        0        0   \n",
       "C8    0       0        0        0        0        0        0        0   \n",
       "\n",
       "    70%-80%  80%-90%  90%-100%  \n",
       "C1        0        0         0  \n",
       "C2        0        0         0  \n",
       "C3        0        0         0  \n",
       "C4        0        0         0  \n",
       "C5        0        0         0  \n",
       "C6        0        0         0  \n",
       "C7        0        0         0  \n",
       "C8        0        0         0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confidence_intervals=['<1%',\n",
    "                      '1%-10%',\n",
    "                      '10%-20%',\n",
    "                      '20%-30%',\n",
    "                      '30%-40%',\n",
    "                      '40%-50%',\n",
    "                      '50%-60%',\n",
    "                      '60%-70%',\n",
    "                      '70%-80%',\n",
    "                      '80%-90%',\n",
    "                      '90%-100%']\n",
    "\n",
    "#success_confidence_matrix= pd.DataFrame(0,index=target_list,columns=confidence_intervals)\n",
    "success_confidence_matrix= pd.DataFrame(0,index=dummy_target_list,columns=confidence_intervals)\n",
    "success_confidence_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1505c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&lt;1%</th>\n",
       "      <th>1%-10%</th>\n",
       "      <th>10%-20%</th>\n",
       "      <th>20%-30%</th>\n",
       "      <th>30%-40%</th>\n",
       "      <th>40%-50%</th>\n",
       "      <th>50%-60%</th>\n",
       "      <th>60%-70%</th>\n",
       "      <th>70%-80%</th>\n",
       "      <th>80%-90%</th>\n",
       "      <th>90%-100%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    <1%  1%-10%  10%-20%  20%-30%  30%-40%  40%-50%  50%-60%  60%-70%  \\\n",
       "C1    0       0        0        0        0        0        0        0   \n",
       "C2    0       0        0        0        0        0        0        0   \n",
       "C3    0       0        0        0        0        0        0        0   \n",
       "C4    0       0        0        0        0        0        0        0   \n",
       "C5    0       0        0        0        0        0        0        0   \n",
       "C6    0       0        0        0        0        0        0        0   \n",
       "C7    0       0        0        0        0        0        0        0   \n",
       "C8    0       0        0        0        0        0        0        0   \n",
       "\n",
       "    70%-80%  80%-90%  90%-100%  \n",
       "C1        0        0         0  \n",
       "C2        0        0         0  \n",
       "C3        0        0         0  \n",
       "C4        0        0         0  \n",
       "C5        0        0         0  \n",
       "C6        0        0         0  \n",
       "C7        0        0         0  \n",
       "C8        0        0         0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#failure_confidence_matrix= pd.DataFrame(0,index=target_list,columns=confidence_intervals)\n",
    "failure_confidence_matrix= pd.DataFrame(0,index=dummy_target_list,columns=confidence_intervals)\n",
    "failure_confidence_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc4c968",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "accuracy_confidence_matrix= pd.DataFrame(0.0,index=target_list,columns=confidence_intervals)\n",
    "accuracy_confidence_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a92fc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb69efe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_matching_confidence_score(conf_score):\n",
    "    if(conf_score<=0.01):\n",
    "        return 0\n",
    "    else:\n",
    "        return math.ceil(conf_score*10.0)\n",
    "    \n",
    "get_index_matching_confidence_score(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed3fbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd161d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6f7111",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = 0\n",
    "for idx in range(val_df.shape[0]):\n",
    "    text=[]\n",
    "    \n",
    "    text += preprocess( str(val_df[''].iloc[idx]) )\n",
    "    text += preprocess( str(val_df[''].iloc[idx]) )\n",
    "    text += preprocess( str(val_df[''].iloc[idx]) )\n",
    "    text += preprocess( str(val_df[''].iloc[idx]) )\n",
    "\n",
    "    ### get the ground truth label\n",
    "    ground_truth = val_df[''].iloc[idx]\n",
    "    if ground_truth not in target_list:\n",
    "        print(f\"{ground_truth} not found in target list\")\n",
    "        ground_truth = 'noise'\n",
    "\n",
    "\n",
    "    ### process each sentence in text\n",
    "    prediction_text = {}\n",
    "    \n",
    "    txt=''\n",
    "    for element in text:\n",
    "        txt += element\n",
    "        \n",
    "    encodings = tokenizer.encode_plus(\n",
    "        txt,\n",
    "        None,\n",
    "        add_special_tokens=True,\n",
    "        max_length=MAX_LEN,\n",
    "        padding='max_length',\n",
    "        return_token_type_ids=True,\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input_ids = encodings['input_ids'].to(device, dtype=torch.long)\n",
    "        attention_mask = encodings['attention_mask'].to(device, dtype=torch.long)\n",
    "        token_type_ids = encodings['token_type_ids'].to(device, dtype=torch.long)\n",
    "        output = model(input_ids, attention_mask, token_type_ids)\n",
    "        final_output = torch.sigmoid(output).cpu().detach().numpy().tolist()\n",
    "\n",
    "        curr_conf_score = max(final_output[0])\n",
    "        pred_label = target_cols[int(np.argmax(final_output, axis=1))]\n",
    "\n",
    "        if pred_label:\n",
    "            if not pred_label == 'noise':\n",
    "                if pred_label in prediction_text:\n",
    "                    if prediction_text[pred_label] < curr_conf_score:\n",
    "                        prediction_text[pred_label] = curr_conf_score\n",
    "                else:\n",
    "                    prediction_text[pred_label] = curr_conf_score  \n",
    "\n",
    "    \n",
    "    ### CORNER CASE --- IF MODEL DOES NOT PREDICT ANY LEVEL 1 CATEGORY, THEN SET A \n",
    "    ### DEFAULT CATEGORY AS 'UNCLEAR' --- THIS WILL MAKE SURE CODE WILL NOT BREAK\n",
    "    if len(list(prediction_text.keys())):\n",
    "        predicted_label = max(prediction_text, key=prediction_text.get) \n",
    "    else:\n",
    "        predicted_label = 'noise'\n",
    "    \n",
    "    output_list += (prediction_text, predicted_label, ground_truth, idx)\n",
    "    \n",
    "    if predicted_label == ground_truth:\n",
    "        ct += 1\n",
    "        if ground_truth == 'noise':\n",
    "            TN += 1\n",
    "        else:\n",
    "            TP += 1\n",
    "    else:\n",
    "        if ground_truth == 'noise':\n",
    "            FP += 1\n",
    "        else:\n",
    "            FN += 1\n",
    "\n",
    "    \n",
    "    confusion_matrix[ground_truth][predicted_label] += 1\n",
    "    \n",
    "    l1_softmax_preds=final_output[0]\n",
    "    \n",
    "    for cat_index in range(len(l1_softmax_preds)):\n",
    "        conf_score=l1_softmax_preds[cat_index]\n",
    "        current_cat_name=target_list[cat_index]\n",
    "        interval_index=get_index_matching_confidence_score(conf_score)\n",
    "        matrix_to_increment = success_confidence_matrix if (current_cat_name == ground_truth) else failure_confidence_matrix\n",
    "        conf_interval_col_name=matrix_to_increment.columns[interval_index]\n",
    "        matrix_to_increment.loc[current_cat_name,conf_interval_col_name] += 1\n",
    "\n",
    "print(ct)\n",
    "#print(output_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa8b316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# success_confidence_matrix=success_confidence_matrix.rename(columns={'10%-20':'10%-20%', '20%-30':'20%-30%' })\n",
    "success_confidence_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecca3f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# failure_confidence_matrix=failure_confidence_matrix.rename(columns={'10%-20':'10%-20%', '20%-30':'20%-30%' })\n",
    "failure_confidence_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf5ad5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct/val_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48e36d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87ebf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a3edac",
   "metadata": {},
   "outputs": [],
   "source": [
    "(TP*100.0)/(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5cd064",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7713b5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import seaborn as sns\n",
    "\n",
    "def save_df_as_image(df, path):\n",
    "    # Make plot\n",
    "    plot = sns.heatmap(df,\n",
    "                       annot=True,\n",
    "                       cmap=\"Blues\",\n",
    "                       linewidth=0.5,\n",
    "                       cbar=False,\n",
    "                       robust=True,\n",
    "                       fmt=\"d\")\n",
    "    plot.set_xlabel('Ground Truth')\n",
    "    plot.set_ylabel('Predicted Category')\n",
    "    fig = plot.get_figure()\n",
    "    fig.savefig(path,bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3f7ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df_as_image(confusion_matrix,\"confusion_matrix_roberta_l1_cat_clt.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fa8cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = (TP * 100.0)/(TP + FP)\n",
    "recall = (TP * 100.0)/(TP + FN)\n",
    "{\"Precision\":precision, \"Recall\":recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600d7cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions=pd.Series(0.0,index=confusion_matrix.index)\n",
    "recalls=pd.Series(0.0,index=confusion_matrix.index)\n",
    "for index in precisions.index:\n",
    "    precisions[index]=(confusion_matrix[index][index]*100.0)/sum(confusion_matrix.loc[index])\n",
    "    recalls[index]=(confusion_matrix[index][index])*100.0/sum(confusion_matrix[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478edd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139b76df",
   "metadata": {},
   "outputs": [],
   "source": [
    "recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555348a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics=pd.DataFrame(0,index=confusion_matrix.index,columns=['precision','recall'])\n",
    "metrics['precision']=precisions\n",
    "metrics['recall']=recalls\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7e398d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_confidence_matrix=accuracy_confidence_matrix.rename(columns={'10%-20':'10%-20%', '20%-30':'20%-30%' })\n",
    "for column in accuracy_confidence_matrix.columns:\n",
    "    for index in accuracy_confidence_matrix.index:\n",
    "        numerator = success_confidence_matrix[column][index]\n",
    "        denominator = failure_confidence_matrix[column][index] + numerator\n",
    "        if denominator == 0:\n",
    "            accuracy_confidence_matrix.loc[index,column] = np.NINF\n",
    "        else:\n",
    "            accuracy_confidence_matrix.loc[index,column]=float(numerator)/denominator\n",
    "\n",
    "accuracy_confidence_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433c53a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metaconfidence_row_name='metaconfidence'\n",
    "overall_metaconfidence=pd.DataFrame(0.0,index=[metaconfidence_row_name],columns=accuracy_confidence_matrix.columns)\n",
    "overall_metaconfidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab21af51",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in success_confidence_matrix:\n",
    "    addendum_list=success_confidence_matrix[column].tolist()\n",
    "    for idx in range(len(addendum_list)):\n",
    "        if addendum_list[idx]==np.NINF:\n",
    "            addendum_list[idx]=0\n",
    "    numerator=sum(addendum_list)\n",
    "    addendum_list=failure_confidence_matrix[column].tolist()\n",
    "    for idx in range(len(addendum_list)):\n",
    "        if addendum_list[idx]==np.NINF:\n",
    "            addendum_list[idx]=0\n",
    "    denominator=sum(addendum_list) + numerator\n",
    "    if denominator == 0:\n",
    "        overall_metaconfidence.loc[metaconfidence_row_name,column]=np.NINF\n",
    "    else:\n",
    "        overall_metaconfidence.loc[metaconfidence_row_name,column]=float(numerator*100)/denominator\n",
    "overall_metaconfidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293ada70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_wise_metrics = ['misclassifications','matches','category_cases','accuracy']\n",
    "# cat_wise_acc = pd.DataFrame(None,index=multiclass_target_list,columns=cat_wise_metrics)\n",
    "# cat_wise_acc\n",
    "# for cat in multiclass_target_list: \n",
    "#     cat_wise_acc.loc[cat,'category_cases'] = sum(confusion_matrix[cat])\n",
    "#     cat_wise_acc.loc[cat,'matches'] = confusion_matrix[cat][cat]\n",
    "#     cat_wise_acc.loc[cat,'misclassifications'] = sum(confusion_matrix[cat]) - confusion_matrix[cat][cat]\n",
    "#     cat_wise_acc.loc[cat,'accuracy'] = (cat_wise_acc.loc[cat,'matches'] * 100.0) / cat_wise_acc.loc[cat,'category_cases']\n",
    "# cat_wise_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d4e064",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ffbb16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
